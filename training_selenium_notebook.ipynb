{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Selenium\n",
    "Selenium automates the extraction of content (scraping) from emails and skype conversation, by recreating the process of scrolling-clicking-copying-pasting conversations - something that would otherwise have to be done by an obedient employee.\n",
    "\n",
    "Messages from Outlook and Skype are formatted into a tabular form\n",
    "\n",
    "<img src=\"images_inkscape/tabular_form_selenium.png\" style=\"width: 1000px;\">\n",
    "\n",
    "***\n",
    "\n",
    "<font color=red><b>The notebook parallels the <a href=\"./adv04_selenium_skypeOutlook.pdf\" ><b>PDF Report<b></a></b></font>. Use the report as the main learning source, and this notebook for practical examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 1 - Packages\n",
    "Using selenium requires the:\n",
    "- `selenium` package for creating a Chrome instance and communicating with it;\n",
    "- `bs4` <code>(BeautifulSoup)</code> package for efficient extraction;\n",
    "- `Chrome` must be installed\n",
    "- `chromedriver` to launch a Chrome instance that can be controlled through python\n",
    "And what sucks, is that a full Chrome window will genuinely have to open, hitting your RAM. Expect your fans to produce an airplane noise ‚úà\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 2 - Standard call to create a Chrome <font color=red><b>driver</b></font>\n",
    "This is a standard call that has to start every `selenium` session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def load_driver():\n",
    "    # 1 - set options and capabilities for Chrome\n",
    "    capabilities = {'chromeOptions':\n",
    "                                      {\n",
    "                                          'useAutomationExtension': False,\n",
    "                                          'args': ['--disable-extensions']}\n",
    "                                      }     \n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_experimental_option(\"prefs\", {\n",
    "        \"download.prompt_for_download\":   False,\n",
    "        \"download.directory_upgrade\":     True,\n",
    "        \"safebrowsing.enabled\":           True\n",
    "    })\n",
    "\n",
    "    # 2 - create a driver instance with defined options\n",
    "    driver = webdriver.Chrome(executable_path=\"./chromedriver\",\n",
    "                               desired_capabilities=capabilities,\n",
    "                              options=chrome_options)\n",
    "\n",
    "    driver.maximize_window()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 3 - Accessing webpages\n",
    "Following a succesful driver creation, a page is accessed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 1 - load driver and max \n",
    "driver = load_driver()\n",
    "\n",
    "# 2 - load url and \n",
    "driver.get(\"https://en.wikipedia.org/wiki/Demon_core\")\n",
    "\n",
    "# 3 - close\n",
    "time.sleep(2)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 4 - Structure of HTML\n",
    "All the functionality of selenium resides in the ability of interacting with the `html` of the webpage which is viewed by doing\n",
    "<center><font color=red size=4><b>Right Click ‚Üí Inspect ‚Üí Element Selector</b></font></center>\n",
    "\n",
    "Below is the html for the selection in the image:\n",
    "```html\n",
    "\n",
    "\n",
    "<div id=\"toc\" class=\"toc\">\n",
    "\t<input type=\"checkbox\" role=\"button\" id=\"toctogglecheckbox\" class=\"toctogglecheckbox\" style=\"display:none\">\n",
    "\t<div class=\"toctitle\" lang=\"en\" dir=\"ltr\">\n",
    "\t\t<h2>Contents</h2>\n",
    "\t\t<span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span>\n",
    "\t</div>\n",
    "\t<ul>\n",
    "\t\t<li class=\"toclevel-1 tocsection-1\"><a href=\"#Manufacturing_and_early_history\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Manufacturing and early history</span></a></li>\n",
    "\t\t<li class=\"toclevel-1 tocsection-2\"><a href=\"#First_incident\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">First incident</span></a></li>\n",
    "\t\t<li class=\"toclevel-1 tocsection-3\">\n",
    "\t\t\t<a href=\"#Second_incident\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Second incident</span></a>\n",
    "\t\t\t<ul>\n",
    "\t\t\t\t<li class=\"toclevel-2 tocsection-4\"><a href=\"#Medical_studies\"><span class=\"tocnumber\">3.1</span> <span class=\"toctext\">Medical studies</span></a></li>\n",
    "\t\t\t</ul>\n",
    "\t\t</li>\n",
    "\t</ul>\n",
    "</div>\n",
    "```\n",
    "\n",
    "***\n",
    "<img src=\"images_inkscape/html_example.png\" style=\"width: 1000px;\">\n",
    "\n",
    "***\n",
    "\n",
    "As seen, `html` has a layered structure. The job is to traverse through these layers, which is done with either:\n",
    "- `xPaths` to grab elements for clicking, filling, or any other interaction\n",
    "- `BeautifulSoup` to extract text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 5 - Extraction with `xPaths`: use when elements need to be interacted with or fully loaded\n",
    "\n",
    "An `xPath` is a string that directs a html search. Consult the pdf `xPath` chapter for more details.\n",
    "\n",
    "<img src=\"images_inkscape/xpath_anatomy_example.png\">\n",
    "\n",
    "It is built using\n",
    "- <font color=red><b>Nodes</b></font> e.g. `/div` `/img` `/span` `/button`\n",
    "- <font color=red><b>Attributes</b></font> e.g. `/id[@id=\"bannerCnt\"]`\n",
    "- <font color=red><b>Indicies (starting from 1)</b></font> e.g. `/id[2]` or `id[last()-1]`\n",
    "\n",
    "A wilcard `*` or `@*` matches any node or attribute.\n",
    "\n",
    "***\n",
    "## Performing the search\n",
    "With an xPath built, single elements are <font color=red>webElements</font> are located with\n",
    "```python\n",
    "webelement = driver.find_element_by_xpath(xpath)\n",
    "```\n",
    "and multiple elements are located with\n",
    "```python\n",
    "webelementS = driver.find_elements_by_xpath(xpath)\n",
    "```\n",
    "<font color=red><b>Webelements</b></font> are needed for clicking and other forms of interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¶ø Title webelement:  <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"71748a84-996b-4134-adfd-639d77fe9e06\")>\n",
      "‚¶ø Sidebar links:\t [<selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"00a01135-46f5-4741-b7d0-b63e9c32a6aa\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"7e39d823-1323-4949-9d53-a7568f633a19\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"1ba645ec-faba-488d-aa46-a1906f129db0\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"82e30490-f04e-4759-a250-f09f550a16a1\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"3669d44b-7a5e-4c84-9dd7-232da11be9c1\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"aee922b6-bfcb-4acd-9988-8bb2c8ea9c8d\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c9d6e23000f0586e0bbd43e51feb3bbc\", element=\"cd14e28e-ea5f-41b5-acd6-106045c00d9e\")>]\n",
      "‚¶ø Sidebar links:\t []\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# üçè Search elements with xPaths\n",
    "########################################\n",
    "driver=load_driver()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/Demon_core\")\n",
    "\n",
    "# 1 - get the title\n",
    "xpath_title = \"//h1[@id='firstHeading']\"\n",
    "title = driver.find_element_by_xpath(xpath_title)\n",
    "print(\"‚¶ø Title webelement: \", title.text)\n",
    "\n",
    "# 2 - get the links on side of page\n",
    "xpath_links = \"//div[@id='p-navigation' and @role='navigation']/div/ul/li/a\"\n",
    "links = driver.find_elements_by_xpath(xpath_links)\n",
    "print(\"‚¶ø Sidebar links:\\t\", links.text)\n",
    "\n",
    "# 3 - get the top link in sidebar\n",
    "xpath_top = \"//div[@id='p-navigation' and @role='navigation']/div/ul/li[0]/a\"\n",
    "top = driver.find_elements_by_xpath(xpath_top)\n",
    "print(\"‚¶ø Sidebar links:\\t\", top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Interaction with Webelements\n",
    "The most common ways of interacting with webElements is:\n",
    "- `webelement.click()`\n",
    "- `webelement.send_keys(\"What to send\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# üçè Using the extracted webelements\n",
    "########################################\n",
    "# 1 - click on \"main page\" link\n",
    "driver.find_element_by_xpath(\"//div[@id='p-navigation' and @role='navigation']/div/ul/li[1]/a\").click()\n",
    "\n",
    "# 2 - fill search box\n",
    "xpath_search = \"//*[@id='searchInput']\"\n",
    "search = driver.find_element_by_xpath(xpath_search)\n",
    "search.send_keys(\"1934\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# üìî xpaths to automate ebay\n",
    "########################################\n",
    "# 1 - create a selenium driver and navigate to the supplied url\n",
    "url = \"https://www.ebay.com\"\n",
    "\n",
    "# 2 - use xpaths to search for a user supplied object\n",
    "item = input(\"üí∞ I want to buy: \")\n",
    "\n",
    "# 3 - use xpaths to tick the \"buy it now\" box and click on the top object\n",
    "\n",
    "# 4 - click buy it now and stop there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 7 - Extraction with `BeautifulSoup` - use when text needs to be extracted from the webpage\n",
    "\n",
    "`xPaths` are great for interacting with elements on the page, however practically any kind of text extraction is easier and less confusing with `BeautifulSoup`.\n",
    "\n",
    "There is a single preparations stage with BeautifulSoup - convert the HTML into an internal format used by `BeautifulSoup`\n",
    "\n",
    "```python\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "```\n",
    "***\n",
    "\n",
    "Once formatting is done, the `find` and `findall` functions can be used to extract elements\n",
    "```python\n",
    "single_structure = soup.find(\"div\", attrs={\"role\": \"option\"})\n",
    "multiple_structures = soup.find_all(\"span\", attrs={\"role\": \"option\", \"style\": \"\n",
    "                                     aria-label\": \"Reading Pane\"})\n",
    "```\n",
    "\n",
    "<font color=red><b>Each return is another BeautifulSoup object that can be searched, and thus a recursive call can be setup to navigate down the HTML layers</b></font>\n",
    "\n",
    "***\n",
    "\n",
    "Text extraction is run on the elements obtained\n",
    "```python\n",
    "multiple_structures = #Block from above example\n",
    "unpacked_text = [i.get_text().strip() for i in multiple_structures]\n",
    "```\n",
    "\n",
    "Tag extraction works in a similar way\n",
    "```python\n",
    "unpacked_tag = structure.get(\"href\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_elements(soup, search):\n",
    "    \"\"\"\n",
    "    __ Parameters __\n",
    "    [soup] soup:                object to extract\n",
    "    [1D-dict] search:           {\"node\":        [str] node,\n",
    "                                 \"attributes\":  [dict] of attribute - value}\n",
    "    __ Description __\n",
    "    searches through the supplied layers and returns the soup objects\n",
    "    __ Return __\n",
    "    [1D-soup] objects that fit criteria\n",
    "    \"\"\"\n",
    "    return_val = -1\n",
    "    # 1 - already in final layer\n",
    "    if (len(search) == 1):\n",
    "        unpacked_elements = soup\n",
    "    else:\n",
    "        # 2 - unpack intermediate layers\n",
    "        for i in search[:-1]:\n",
    "            unpacked_elements = soup.find(i['node'], attrs=i['attributes'])\n",
    "    # 3 - unpack the final layer    \n",
    "    return unpacked_elements.find_all(search[-1]['node'], attrs=search[-1]['attributes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "########################################\n",
    "# üçè Example of instagram scraping (if you have account)\n",
    "########################################\n",
    "hashtag = \"üçëüçëüçëüçë\"\n",
    "\n",
    "# 1 - load hashtag\n",
    "driver=load_driver()\n",
    "driver.get('https://www.instagram.com/explore/tags/'+hashtag)\n",
    "\n",
    "# 2 - load webpage into BeautifulSoupK\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 3 - extract images located in body -> span -> a\n",
    "search = [{\"node\": \"body\",\n",
    "           \"attributes\": None},\n",
    "          {\"node\": \"span\",\n",
    "           \"attributes\": None},\n",
    "          {\"node\": \"a\",\n",
    "           \"attributes\": None}]\n",
    "image_structures = extract_elements(soup, search)\n",
    "\n",
    "# 4 - search for \"img\" and the following src=https://scontent-hkg3-1.cdninstagram.co...\"\"\n",
    "image_url = []\n",
    "for i in image_structures:\n",
    "    mg = re.search('img.*src=\\\"(.+?)\\\"', str(i))\n",
    "    if(mg):\n",
    "        image_url.append(mg.group(1))\n",
    "        \n",
    "# 5 - request images\n",
    "for idx, i in enumerate(image_url[:10]):\n",
    "    r = requests.get(i)\n",
    "    with open(f\"instagram_images/{idx+1}.jpg\", 'wb') as fout:\n",
    "        fout.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# üìî Wikipedia scraping\n",
    "########################################\n",
    "# 1 - load driver and direct to wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/Main_Page\"\n",
    "\n",
    "# 2 - scrape all the words that are on the page\n",
    "#   - split them by spaces into a list\n",
    "word_list = None\n",
    "\n",
    "# üóë Removing junk\n",
    "# 3 - remove anything in the list after \"Refferences\" (regexp search for refferences)\n",
    "for i in word_list:\n",
    "    pass\n",
    "\n",
    "# 4 - keep only a-z words (once againm regexp)\n",
    "for i in word_list:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 8 - Wait functionality\n",
    "Waiting on elements is a very important procedure, since certain elements of the page may not be loaded in time for clicking or reading operations. This is handled by the `WebDriverWaiter`:\n",
    "\n",
    "```python\n",
    "timeout = 50 # timeout given in seconds\n",
    "web_waiter = WebDriverWait(driver , timeout)\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "The most basic check involves checking for the presence of an xpath:\n",
    "```python\n",
    "WebDriverWaiter.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "```\n",
    "\n",
    "***\n",
    "However most likely a separate class would be defined to wait on a specific event to occur.\n",
    "- <font color=red><b>Must have a function called</b> <code>_call(driver)__</code> that takes <code>driver</code> as a parameter</font>\n",
    "- Returns `True` once a condition is satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWaiter\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "class wait_for_change():\n",
    "  \"\"\"\n",
    "  waits on the text of the specified xpath to change from it's old value\n",
    "\n",
    "  __Use-case__\n",
    "  a field is due to be updated, but is suffering from some lag\n",
    "\n",
    "  __Usage__\n",
    "  WebDriverWaitINSTANCE.until(wait_for_content_change(XPATH, OLD_TEXT))\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, xpath, old_text):\n",
    "      \n",
    "      self.xpath = xpath\n",
    "      self.old_text = old_text\n",
    "  \n",
    "  def __call__(self, driver):\n",
    "\n",
    "    try:\n",
    "      # 1 - get the content on the chosen xpath\n",
    "      curret_text = EC._find_element(driver, self.xpath).text.strip()\n",
    "      \n",
    "      # 2 - check if value changed or is zero\n",
    "      return = ((curret_text != \"\" ) and (curret_text != self.old_text))\n",
    "\n",
    "    # 3 - pass on error of not catching anything\n",
    "    except StaleElementReferenceException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# üìî Integrate  check to Google Translate on the set of words\n",
    "########################################\n",
    "translate_list = [\"The\", \"industrial\", \"revolution\", \"has\", \"been\", \"a\", \"disaster\", \"for\", \"human\", \"race\"]\n",
    "timeout = 50 # timeout given in seconds\n",
    "translation_list = []\n",
    "\n",
    "# 1 - load driver and move it to google translate\n",
    "url = \"https://translate.google.com/\"\n",
    "\n",
    "# 2 - create a waiter\n",
    "waiter = WebDriverWait(driver , timeout)\n",
    "\n",
    "# 3 - set the input language to english and output to chinese\n",
    "pass\n",
    "\n",
    "for i in translate_list:\n",
    "    # 4 - go through translate list and write the word to input box\n",
    "    pass\n",
    "\n",
    "    # 5 - wait for translation to occur using the above \"wait_for_change_class\"\n",
    "    # waiter.until(wait_for_change(\"üçÑXPATHüçÑ\", \"üçÑOLDVALUEüçÑ\"))\n",
    "\n",
    "    # 6 - extract the translation and add it to list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "For a specific example of Skype and Outlook bots in action <a href=\"./material_selenium_notebook_EXAMPLES.ipynb\"><b>See this example notebook</b></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "material_selenium_notebook.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
